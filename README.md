# Movies-ETL
Automated Extraction, Transformation and Load (ETL) pipeline for movies challenge.
A data pipeline moves data from a source to a destination, and the ETL process creates data pipelines that also helps to transform the data along the way.

## Project Overview
Amazing Prime video, an online streaming service, has decided to sponser a Hackathon. Given a set of clean movie data, the task is to predict the popular films. The first step is to collect the data by extracting it from the web and transforming it and then transform the data to be more usable. Second, the data needs to be loaded into a SQL Database.

## Tools
Python, Pandas, SQL, PostgreSQL, Jupyter notebook

## Summary

The ETL (Extract, Transform, Load) process is an essential pipeline for data analysis. In order to analyze data, it must be collected, cleaned, and structured. This translates to extracting raw data from sources, cleaning and structuring the data into a desired form, and finally storing the data in a database. This module dealt with three data sources and involved extracting the raw data from these files, individually cleaning them, then transforming them into a single structure which is then stored as a SQL database. 
The challenge comes when combining data from multiple sources and the involved process of cleaning the data. When it comes to raw data, it is typically messy, meaning there could be NaN's, incorrect, or incomplete data. Then comes the transform step which deals with this messy data with the goal of structuring it in a way that can be easily written to a database. The extract and transform steps can be iterative meaning there may be multiple rounds of data collection and manipulation. 


![example](https://user-images.githubusercontent.com/75762456/110231400-3101b600-7edd-11eb-8576-354b21489741.PNG)
![sqltable](https://user-images.githubusercontent.com/75762456/110231423-4bd42a80-7edd-11eb-8f8d-70cc4acd602a.PNG)
